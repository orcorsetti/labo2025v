{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/orcorsetti/labo2025v/blob/main/src/ensembles/420_ArbolesAzarosos_Bayesian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Ensembles de Arboles de Decision"
      ],
      "metadata": {
        "id": "kgJ0E--L0n9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un arbol de decisión es un modelo débil, el aumento del poder predictivo proviene al ensamblar varios arboles de decisión.\n",
        "<br> Si promedio n arboles identicos, el resultados es exactamente el mismo que utilizar un solo arbol, necesito PERTURBAR cada arbol para disponer de variablidad"
      ],
      "metadata": {
        "id": "PgLdmWznXWGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "la variabilidad provendrá de estas fuentes:\n",
        "\n",
        "\n",
        "*   Perturbar el dataset\n",
        "*   Perturbar el algoritmo del arbol\n",
        "*   Perturbar el dataset y el algoritmo del arbol al mismo tiempo"
      ],
      "metadata": {
        "id": "FTnxMEOqYRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se verán estos tres algoritmos\n",
        "\n",
        "\n",
        "*   Arboles Azarosos\n",
        "*   Random Forest\n",
        "*   Gradient Boosting of Decision Trees"
      ],
      "metadata": {
        "id": "DHp1h9m-X7Rc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m0ySYPfa7Zr"
      },
      "source": [
        "#### 4.01 Seteo del ambiente en Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGY7H9xza7Zr"
      },
      "source": [
        "Esta parte se debe correr con el runtime en Python3\n",
        "<br>Ir al menu, Runtime -> Change Runtime Type -> Runtime type ->  **Python 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PupIBNba7Zr"
      },
      "source": [
        "Conectar la virtual machine donde esta corriendo Google Colab con el  Google Drive, para poder tener persistencia de archivos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LpZCst5a7Zs"
      },
      "outputs": [],
      "source": [
        "# primero establecer el Runtime de Python 3\n",
        "from google.colab import drive\n",
        "drive.mount('/content/.drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYC_F-wla7Zs"
      },
      "source": [
        "Para correr la siguiente celda es fundamental en Arranque en Frio haber copiado el archivo kaggle.json al Google Drive, en la carpeta indicada en el instructivo\n",
        "\n",
        "<br>los siguientes comando estan en shell script de Linux\n",
        "*   Crear las carpetas en el Google Drive\n",
        "*   \"instalar\" el archivo kaggle.json desde el Google Drive a la virtual machine para que pueda ser utilizado por la libreria  kaggle de Python\n",
        "*   Bajar el  **dataset_pequeno**  al  Google Drive  y tambien al disco local de la virtual machine que esta corriendo Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWLelftXa7Zt"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p \"/content/.drive/My Drive/labo1\"\n",
        "mkdir -p \"/content/buckets\"\n",
        "ln -s \"/content/.drive/My Drive/labo1\" /content/buckets/b1\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "cp /content/buckets/b1/kaggle/kaggle.json  ~/.kaggle\n",
        "chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "\n",
        "mkdir -p /content/buckets/b1/exp\n",
        "mkdir -p /content/buckets/b1/datasets\n",
        "mkdir -p /content/datasets\n",
        "\n",
        "\n",
        "\n",
        "archivo_origen=\"https://storage.googleapis.com/open-courses/austral2025-af91/dataset_pequeno.csv\"\n",
        "archivo_destino=\"/content/datasets/dataset_pequeno.csv\"\n",
        "archivo_destino_bucket=\"/content/buckets/b1/datasets/dataset_pequeno.csv\"\n",
        "\n",
        "if ! test -f $archivo_destino_bucket; then\n",
        "  wget  $archivo_origen  -O $archivo_destino_bucket\n",
        "fi\n",
        "\n",
        "\n",
        "if ! test -f $archivo_destino; then\n",
        "  cp  $archivo_destino_bucket  $archivo_destino\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc9x9DnsNlZv"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.02 Arboles Azarosos"
      ],
      "metadata": {
        "id": "qq0KVOtq1K5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arboles Azarosos es el nombre de un algoritmo trivial (por favor NO confundir con Random Forest)\n",
        "Qué tipo de perturbaciones se realizan en Arboles Azarosos\n",
        "* Se perturba el dataset\n",
        "* No se perturba el algoritmo, es siempre rpart original"
      ],
      "metadata": {
        "id": "HsNJjhlRo9jM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cada  arbolito de  Arboles Azarosos se entrena sobre un dataset perturbado,  que tiene exactamente la misma cantidad de registros pero solo un subconjunto de los atributos (campos)  del dataset, tomados al azar, de los originales.\n",
        "<br> En esta primera corrida, se construira cada arbol en un dataset utilizando el 50% de los campos"
      ],
      "metadata": {
        "id": "rq2HC28CpXBR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSU5vi00CPRS"
      },
      "source": [
        "Esta parte se debe correr con el runtime en lenguaje **R** Ir al menu, Runtime -> Change Runtime Type -> Runtime type -> R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8dySimCPRT"
      },
      "source": [
        "limpio el ambiente de R"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "LrdtraBYJrsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iE0U4_WCPRT"
      },
      "outputs": [],
      "source": [
        "# limpio la memoria\n",
        "rm(list=ls(all.names=TRUE)) # remove all objects\n",
        "gc(full=TRUE, verbose=FALSE) # garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJDwdD0dCPRU"
      },
      "outputs": [],
      "source": [
        "# cargo las librerias que necesito\n",
        "require(\"data.table\")\n",
        "require(\"rpart\")\n",
        "require(\"parallel\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if( ! require(\"rlist\") ) install.packages(\"rlist\")\n",
        "require(\"rlist\")"
      ],
      "metadata": {
        "id": "Npcefp7r0wG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paquete necesarios para la Bayesian Optimization\n",
        "if( !require(\"DiceKriging\") ) install.packages(\"DiceKriging\")\n",
        "require(\"DiceKriging\")"
      ],
      "metadata": {
        "id": "ViNckm6i0xk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# paquete necesarios para la Bayesian Optimization\n",
        "if( !require(\"mlrMBO\") ) install.packages(\"mlrMBO\")\n",
        "require(\"mlrMBO\")"
      ],
      "metadata": {
        "id": "GsUkXtFL00Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defino la  Optimizacion Bayesiana\n",
        "\n",
        "# cantidad de iteraciones de la Optimizacion Bayesiana\n",
        "PARAM <- list()\n",
        "\n",
        "PARAM$semilla_primigenia <- 100183\n",
        "PARAM$experimento <- \"HT310\"\n",
        "\n",
        "PARAM$BO_iter <- 40 #cantidad de iteraciones de la Bayesian Optimization\n",
        "\n",
        "# la letra L al final de 1L significa ENTERO\n",
        "PARAM$hs <- makeParamSet(\n",
        "    makeNumericParam(\"cp\", lower= -1, upper= 0.1),\n",
        "    makeIntegerParam(\"minsplit\", lower= 1L, upper= 8000L),\n",
        "    makeIntegerParam(\"minbucket\", lower= 1L, upper= 4000L),\n",
        "    makeIntegerParam(\"maxdepth\", lower= 3L, upper= 20L),\n",
        "    forbidden= quote(minbucket > 0.5 * minsplit)\n",
        ")\n",
        "# minbuket NO PUEDE ser mayor que la mitad de minsplit"
      ],
      "metadata": {
        "id": "3YTR0NYn03Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "dir.create(PARAM$experimento, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", PARAM$experimento ))"
      ],
      "metadata": {
        "id": "z3CQzlgV05ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui debe cargar SU semilla primigenia"
      ],
      "metadata": {
        "id": "M8-Pyp6CCPRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PARAM <- list()\n",
        "PARAM$semilla_primigenia <- 100183\n",
        "\n",
        "# parametros  arbol\n",
        "# entreno cada arbol con solo 50% de las variables variables\n",
        "#  por ahora, es fijo\n",
        "PARAM$feature_fraction <- 0.5\n",
        "\n",
        "PARAM$rpart$cp <- -1\n",
        "PARAM$rpart$minsplit <- 50\n",
        "PARAM$rpart$minbucket <- 20\n",
        "PARAM$rpart$maxdepth <- 6\n",
        "\n",
        "# voy a generar 512 arboles,\n",
        "#  a mas arboles mas tiempo de proceso y MEJOR MODELO,\n",
        "#  pero ganancias marginales\n",
        "PARAM$num_trees_max <- 512"
      ],
      "metadata": {
        "id": "peRH7ySLCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# carpeta de trabajo\n",
        "setwd(\"/content/buckets/b1/exp\")\n",
        "experimento <- \"exp4020\"\n",
        "dir.create(experimento, showWarnings=FALSE)\n",
        "setwd( paste0(\"/content/buckets/b1/exp/\", experimento ))"
      ],
      "metadata": {
        "id": "1gZD6ZMvCPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lectura del dataset\n",
        "dataset <- fread(\"/content/datasets/dataset_pequeno.csv\")"
      ],
      "metadata": {
        "id": "Xi0emX2ECPRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defino los dataset de entrenamiento y aplicacion\n",
        "dtrain <- dataset[foto_mes == 202107]\n",
        "dfuture <- dataset[foto_mes == 202109]\n",
        "\n",
        "# arreglo clase_ternaria por algun distraido \"\"\n",
        "dfuture[, clase_ternaria := NA ]"
      ],
      "metadata": {
        "id": "RA3cSJ6KaGwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Establezco cuales son los campos que puedo usar para la prediccion\n",
        "# el copy() es por la Lazy Evaluation\n",
        "campos_buenos <- copy(setdiff(colnames(dtrain), c(\"clase_ternaria\")))"
      ],
      "metadata": {
        "id": "EByLkVMwaC8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# que tamanos de ensemble grabo a disco\n",
        "grabar <- c(1, 2, 4, 8, 16, 32, 64, 128, 256, 384, 512)"
      ],
      "metadata": {
        "id": "rHMrHwwpaB8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tb_prediccion <- dfuture[, list(numero_de_cliente)]\n",
        "# aqui se va acumulando la probabilidad del ensemble\n",
        "tb_prediccion[, prob_acumulada := 0]"
      ],
      "metadata": {
        "id": "bJHS2aeghw6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(PARAM$semilla_primigenia) # Establezco la semilla aleatoria"
      ],
      "metadata": {
        "id": "H_DGUB_fhzHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6Nqm7qwy15J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EstimarGanancia = function(rpart_params) {\n",
        "    for (arbolito in seq(PARAM$num_trees_max) ) {\n",
        "    message( arbolito, \" \")\n",
        "    qty_campos_a_utilizar <- as.integer(length(campos_buenos)\n",
        "      * PARAM$feature_fraction)\n",
        "\n",
        "    # elijo los campos al azar\n",
        "    campos_random <- sample(campos_buenos, qty_campos_a_utilizar)\n",
        "\n",
        "    # paso de un vector a un string con los elementos\n",
        "    # separados por un signo de \"+\"\n",
        "    # este hace falta para la formula\n",
        "    campos_random <- paste(campos_random, collapse= \" + \")\n",
        "\n",
        "    # armo la formula para rpart\n",
        "    formulita <- paste0(\"clase_ternaria ~ \", campos_random)\n",
        "\n",
        "    # genero el arbol de decision\n",
        "    modelo <- rpart(formulita,\n",
        "      data= dtrain,\n",
        "      xval= 0,\n",
        "      control= rpart_params\n",
        "    )\n",
        "\n",
        "    # aplico el modelo a los datos que no tienen clase\n",
        "    prediccion <- predict(modelo, dfuture, type= \"prob\")\n",
        "\n",
        "    tb_prediccion[, prob_acumulada := prob_acumulada + prediccion[, \"BAJA+2\"]]\n",
        "\n",
        "    print(tb_prediccion[, Predicted := as.numeric(prob_acumulada > umbral_corte)])\n",
        "\n",
        "    return(tb_prediccion[, Predicted := as.numeric(prob_acumulada > umbral_corte)])\n",
        "\n",
        "    }\n",
        "  }\n",
        "}"
      ],
      "metadata": {
        "id": "j-xp2HQDhFmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archivo_log <- \"BO_log.txt\"\n",
        "archivo_BO <- \"bayesian.RDATA\"\n",
        "\n",
        "# leo si ya existe el log\n",
        "#  para retomar en caso que se se corte el programa\n",
        "GLOBAL_iteracion <- 0\n",
        "GLOBAL_mejor <- -Inf\n",
        "\n",
        "if (file.exists(archivo_log)) {\n",
        "  tabla_log <- fread(archivo_log)\n",
        "  GLOBAL_iteracion <- nrow(tabla_log)\n",
        "  GLOBAL_mejor <- tabla_log[, max(ganancia)]\n",
        "}"
      ],
      "metadata": {
        "id": "GsllfIvUy3QS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aqui comienza la configuracion de la Bayesian Optimization\n",
        "\n",
        "funcion_optimizar <- EstimarGanancia\n",
        "\n",
        "configureMlr(show.learner.output= FALSE)\n",
        "\n",
        "# configuro la busqueda bayesiana,\n",
        "#  los hiperparametros que se van a optimizar\n",
        "# por favor, no desesperarse por lo complejo\n",
        "# minimize= FALSE estoy Maximizando la ganancia\n",
        "obj.fun <- makeSingleObjectiveFunction(\n",
        "  fn= funcion_optimizar,\n",
        "  minimize= FALSE,\n",
        "  noisy= TRUE,\n",
        "  par.set= PARAM$hs,\n",
        "  has.simple.signature= FALSE\n",
        ")\n",
        "\n",
        "ctrl <- makeMBOControl(\n",
        "  save.on.disk.at.time= 600,\n",
        "  save.file.path= archivo_BO\n",
        ")\n",
        "\n",
        "ctrl <- setMBOControlTermination(ctrl, iters= PARAM$BO_iter)\n",
        "ctrl <- setMBOControlInfill(ctrl, crit= makeMBOInfillCritEI())\n",
        "\n",
        "surr.km <- makeLearner(\"regr.km\",\n",
        "  predict.type= \"se\",\n",
        "  covtype= \"matern3_2\", control= list(trace= TRUE)\n",
        ")"
      ],
      "metadata": {
        "id": "hDVl1lRYy7yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inicio la optimizacion bayesiana\n",
        "if (!file.exists(archivo_BO)) {\n",
        "  bayesiana_salida <- mbo(\n",
        "    fun= obj.fun,\n",
        "    learner= surr.km,\n",
        "    control= ctrl\n",
        "  )\n",
        "} else {\n",
        "  bayesiana_salida <- mboContinue(archivo_BO)\n",
        "}\n",
        "# retomo en caso que ya exista"
      ],
      "metadata": {
        "id": "fcF4nzSZ0VsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# almaceno los resultados de la Bayesian Optimization\n",
        "# y capturo los mejores hiperparametros encontrados\n",
        "\n",
        "tb_bayesiana <- as.data.table(bayesiana_salida$opt.path)\n",
        "\n",
        "# ordeno en forma descendente por AUC = y\n",
        "setorder(tb_bayesiana, -y)\n",
        "\n",
        "# grabo para eventualmente poder utilizarlos en OTRA corrida\n",
        "fwrite( tb_bayesiana,\n",
        "  file= \"BO_log.txt\",\n",
        "  sep= \"\\t\"\n",
        ")\n",
        "\n",
        "# los mejores hiperparámetros son los que quedaron en el registro 1 de la tabla\n",
        "PARAM$out$lgbm$mejores_hiperparametros <- tb_bayesiana[\n",
        "  1, # el primero es el de mejor AUC\n",
        "  list(cp, minsplit, minbucket, maxdepth)\n",
        "]\n",
        "\n",
        "print(PARAM$out$lgbm$mejores_hiperparametros)"
      ],
      "metadata": {
        "id": "8YvKC3Zf0kMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format(Sys.time(), \"%a %b %d %X %Y\")"
      ],
      "metadata": {
        "id": "lgmvRHcfJpls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMr6Z1enOyd3"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}